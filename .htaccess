# For full documentation and other suggested options, please see
# http://svn.modxcms.com/docs/display/MODx096/Friendly+URL+Solutions
# including for unexpected logouts in multi-server/cloud environments
# and especially for the first three commented out rules

#php_flag register_globals Off
AddDefaultCharset utf-8
php_value date.timezone Asia/Novosibirsk

#Options +FollowSymlinks
RewriteEngine On
RewriteBase /

# Fix Apache internal dummy connections from breaking [(site_url)] cache
RewriteCond %{HTTP_USER_AGENT} ^.*internal\ dummy\ connection.*$ [NC]
RewriteRule .* - [F,L]

# Redirect http to https
# Способ 1 - для Джино не работает из-за Nginx
#RewriteCond %{HTTP:SSL} !=1 [NC]
#RewriteRule ^(.*) https://%{SERVER_NAME}/$1 [L,R=301]

# Способ 2 - для Джино не работает из-за Nginx
#RewriteCond %{SERVER_PORT} !^443$
#RewriteRule .* https://%{SERVER_NAME}%{REQUEST_URI} [R=301,L]

# Способ 3 - для Джино работает
# Все страницы http с www перенаправляем на https без www
# http://www.domain.com -> https://domain.com
RewriteCond %{HTTP:X-Forwarded-Protocol} !=https
RewriteCond %{REQUEST_URI} !^/robots\.txt$
RewriteCond %{HTTP_HOST} .
RewriteCond %{HTTP_HOST} ^www.(.*)$ [NC]
RewriteRule ^(.*)$ https://%1/$1 [R=301,L]

# Перенаправляем роботс с www и http на http без www (сохраняем пока этот "обычный" роботс для Яндекса)
# http://www.domain.com/robots.txt -> http:/domain.com/robots.txt 
RewriteCond %{HTTP:X-Forwarded-Protocol} !=https
RewriteCond %{REQUEST_URI} ^/robots\.txt$
RewriteCond %{HTTP_HOST} .
RewriteCond %{HTTP_HOST} ^www.(.*)$ [NC]
RewriteRule ^(.*)$ http://%1/$1 [R=301,L]


# Остальные страницы все перенаправляем на https, в нашем случае перенаправятся оставшиеся
# после применения предыдущих правил страницы http без www
# http://domain.com -> https://domain.com
RewriteCond %{HTTP:X-Forwarded-Protocol} !=https
# Некоторое время сохраняем robots.txt доступным и по старому протоколу http (для Яндекса, чтобы не получать сообщение "Не найден файл robots.txt")
RewriteCond %{REQUEST_URI} !^/robots\.txt$
# След. строчка 54 для sitemap (в отличие от строки 50 для роботс) НЕ РАБОТАЕТ.
# Выдает не-ЧПУ адрес с переадресацией на https://aharito.ru/index.php?q=sitemap.xml
# RewriteCond %{REQUEST_URI} !^(/sitemap\.xml)$
RewriteRule .* https://%{SERVER_NAME}%{REQUEST_URI} [R=301,L]


# Rewrite domain.com -> www.domain.com -- used with SEO Strict URLs plugin
#RewriteCond %{HTTP_HOST} .
#RewriteCond %{HTTP_HOST} !^www\.example\.com [NC]
#RewriteRule (.*) http://www.example.com/$1 [R=301,L]

# without www
#RewriteCond %{HTTP_HOST} .
#RewriteCond %{HTTP_HOST} !^aharito\.ru [NC]
#RewriteRule (.*) https://aharito.ru/$1 [R=301,L]

# without www  all domian
#RewriteCond %{HTTP_HOST} .
#RewriteCond %{HTTP_HOST} ^www.(.*)$ [NC]
#RewriteRule ^(.*)$ http://%1/$1 [R=301,L]

# Exclude /assets and /manager directories and images from rewrite rules
RewriteRule ^(manager|assets|js|css|images|img)/.*$ - [L]
RewriteRule \.(jpg|jpeg|png|gif|ico)$ - [L]

# For Friendly URLs
# А здесь стандартные строки
RewriteCond %{REQUEST_FILENAME} !-f
RewriteCond %{REQUEST_FILENAME} !-d
RewriteRule ^(.*)$ index.php?q=$1 [L,QSA]

# Reduce server overhead by enabling output compression if supported.
#php_flag zlib.output_compression On
#php_value zlib.output_compression_level 5
